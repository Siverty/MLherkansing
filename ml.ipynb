{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "from dmba import regressionSummary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset\n",
    "result_df = pd.read_csv(\"./data/results.csv\")\n",
    "stats_df = pd.read_csv(\"./data/status.csv\")\n",
    "drivers_df = pd.read_csv(\"./data/drivers.csv\")\n",
    "races_df = pd.read_csv(\"./data/races.csv\")\n",
    "constructor_df = pd.read_csv(\"./data/constructors.csv\")\n",
    "driver_standings_df = pd.read_csv(\"./data/driver_standings.csv\")\n",
    "qualifying_df = pd.read_csv(\"./data/qualifying.csv\")\n",
    "# pd.get_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the data\n",
    "result_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging all seperate dataframe into single dataframe as df\n",
    "con1 = pd.merge(result_df, races_df, on='raceId')\n",
    "con2 = pd.merge(con1, drivers_df, on='driverId')\n",
    "con3 = pd.merge(con2, driver_standings_df, on=['driverId', 'raceId'])\n",
    "con4 = pd.merge(con3, constructor_df, on='constructorId')\n",
    "con5 = pd.merge(con4, qualifying_df, on=['raceId', 'driverId'])\n",
    "df = pd.merge(con5, stats_df, on=['statusId'])\n",
    "pd.get_option(\"display.max_columns\", None)\n",
    "\n",
    "# checking the data types\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero tables were dropped, there are no null values in this dataframe\n",
    "\n",
    "# checking what types of data are in the dataframe and how much ram they take up\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing the columns in the dataframe\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnecessary columns\n",
    "df = df.drop(['url', 'url_x', 'fastestLapTime', 'positionText_x', 'time_x', 'time_y', 'driverRef', 'constructorRef', 'nationality_y', 'url_y', 'positionText_y', 'points_y', 'rank', 'number_y', 'milliseconds', 'fastestLapSpeed',\n",
    "             'number_x', 'code', 'fastestLap', 'driverStandingsId', 'q1', 'q2', 'q3', 'status', 'constructorId_x', 'constructorId_y', 'points_x', 'qualifyId', 'wins', 'resultId', 'positionOrder', 'position_y', 'grid', 'statusId'], axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the column names to less confusing names\n",
    "\n",
    "col_name = {'name_x': 'grand_prix', 'nationality_x': 'nationality', 'name_y': 'constructor',\n",
    "            'raceId_x': 'racerId', 'points_x': 'points', 'forename': 'firstname', 'position_x': 'finnishPosition'}\n",
    "\n",
    "df.rename(columns=col_name, inplace=True)\n",
    "df.head()\n",
    "\n",
    "# dropping the columns that don't have any value\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the two columns into one column for better readability\n",
    "\n",
    "df['driver_name'] = df.pop('firstname')+' '+df.pop('surname')\n",
    "\n",
    "# # dropping the now unnecessary columns\n",
    "# df = df.drop(['firstname', 'surname'], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to date format from string\n",
    "\n",
    "pd.to_datetime(df.date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting columns into seperate dataframes\n",
    "\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating driver's age and creating it as a new column\n",
    "\n",
    "dates = df['date']-df['dob']\n",
    "age = dates.dt.days/365\n",
    "\n",
    "\n",
    "# rounding the age to the nearest year (for better readability)\n",
    "\n",
    "df['age'] = round(age)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing that the data processing lessens the ram usage (from 43 columns to 26 columns)\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null values\n",
    "\n",
    "df.isnull().sum() / len(df) * 100\n",
    "\n",
    "\n",
    "# since unused there are no null values in this dataframe there has to be no handling of null values but here is the code we used in an earlier build\n",
    "\n",
    "# filling the missing values within columns with the mean value of that column or a 0 if it is a category column\n",
    "\n",
    "# df[['rank', 'fastestLap']] = df[['rank', 'fastestLap']].fillna(0)\n",
    "# df['timetaken_in_millisec'] = df['timetaken_in_millisec'].fillna(\n",
    "#     df['timetaken_in_millisec'].mean())\n",
    "# df['max_speed'] = df['max_speed'].fillna(df['max_speed'].mean())\n",
    "# df['number'] = df['number'].fillna(0)\n",
    "\n",
    "# # checking if null values are still present, if not, then the data is ready to be used (no null values present)\n",
    "\n",
    "# df.isnull().sum() / len(df) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing necessary imports to let the machine actually understand the data\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # encoding the categorical columns\n",
    "\n",
    "# le_grand_prix = LabelEncoder()\n",
    "# le_nationality = LabelEncoder()\n",
    "# le_constructor = LabelEncoder()\n",
    "# le_status = LabelEncoder()\n",
    "# le_driver_name = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # labeling the categorical values\n",
    "\n",
    "# df['grand_prix_n'] = le_grand_prix.fit_transform(df['grand_prix'])\n",
    "# df['nationality_n'] = le_nationality.fit_transform(df['nationality'])\n",
    "# df['constructor_n'] = le_constructor.fit_transform(df['constructor'])\n",
    "# df['status_n'] = le_status.fit_transform(df['status'])\n",
    "# df['driver_name_n'] = le_driver_name.fit_transform(df['driver_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the categorical columns wich contain strings (and other useless columns)\n",
    "\n",
    "# df = df.drop(['grand_prix', 'nationality', 'constructor',\n",
    "#              'status', 'driver_name', 'dob', 'date', 'points'], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping years before 2010 because there was a new points system introduced\n",
    "\n",
    "df.drop(df[df.year < 2010].index, inplace=True)  # consider 2016 as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating categorical and numerical columns for understading\n",
    "\n",
    "cat = []\n",
    "num = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtypes == 'O':\n",
    "        cat.append(i)\n",
    "    else:\n",
    "        num.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical columns\n",
    "\n",
    "for i in cat:\n",
    "    df[i] = le.fit_transform(df[i])\n",
    "df.head()\n",
    "\n",
    "# dropping date and dob columns because they are not needed and they are not numerical\n",
    "\n",
    "df.drop(['date', 'dob'], 1, inplace=True)  # this needs to be placed elsewhere\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'./newdata/collectionfile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the tree structure\n",
    "\n",
    "model = tree.DecisionTreeRegressor(max_depth=5, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating two seperate dataframes for the training and testing data\n",
    "\n",
    "X = pd.DataFrame(df.drop(['finnishPosition'], axis=1))\n",
    "\n",
    "y = pd.DataFrame(df, columns=['finnishPosition'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing a train test split to see if the prediction will be accurate\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(Xtest, ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree = model.predict(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 50 rows of the data vs the predicted values\n",
    "\n",
    "plt.plot([item for item in range(len(ytest[0:50]))], ytest.values[0:50], label=\"Actual Data\", linestyle=':')\n",
    "plt.plot([item for item in range(len(ytest[0:50]))], y_pred_tree[0:50], label=\"Predicted Data\")\n",
    "plt.ylabel(\"FinnishPosition\")\n",
    "plt.xlabel(\"Races\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = list(df.columns)\n",
    "fn.remove('finnishPosition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(150,150))\n",
    "_ = tree.plot_tree(model,\n",
    "               feature_names=fn,\n",
    "               filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"decision_tree.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # removing rows where the driver does not finish the grand prix\n",
    "\n",
    "# df_fin = df[df['status'] == 'Finished']\n",
    "\n",
    "# # showing the end of the dataframe to see if the data is correctly processed\n",
    "\n",
    "# df_fin.tail(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gathering the mean values of the numerical columns to variables\n",
    "\n",
    "# meanMS = df.max_speed.mean()\n",
    "# meanFL = df.fastestLap.mean()\n",
    "\n",
    "# # using values above meanMS in the dataframe to rule out outliers\n",
    "\n",
    "# df = df_fin[df_fin['max_speed'] > meanMS]\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using values above meanFL in the dataframe to rule out outliers\n",
    "\n",
    "# df[df['fastestLap'] > meanFL]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Returns unique values based on a hash table.\n",
    "\n",
    "# df.year.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filtering the data by mean of driver's age and events after year 2012\n",
    "\n",
    "# df = df[(df['age'] < df['age'].mean()) & (df['year'] > 2012)]\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # droping unwanted columns these columns are not needed for the analysis\n",
    "\n",
    "# df.drop('date', 1, inplace=True)\n",
    "# df.drop('dob', 1, inplace=True)\n",
    "# df.drop('statusId', 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Return unbiased skew of the dataframe\n",
    "\n",
    "# df.skew()\n",
    "\n",
    "# # skew is used to determine if the data is normally distributed or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # as can be seen from the above output, the data is not normally distributed, the data will be transformed to normal distribution in the next step\n",
    "\n",
    "# # Q1 and Q3 are the first and third quartiles of the data\n",
    "\n",
    "# Q1 = df.quantile(0.25)\n",
    "# Q3 = df.quantile(0.75)\n",
    "\n",
    "# # IQR is the interquartile range so it is the difference between the Q3 and Q1\n",
    "\n",
    "# IQR = Q3 - Q1\n",
    "\n",
    "# # outliers are the data points that are more than 1.5 times IQR away from the Q1 and Q3 so we will remove them\n",
    "\n",
    "# df = df[~((df < (Q1-1.5*IQR)) | (df > (Q3+1.5*IQR))).any(axis=1)]\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the data is now normally distributed and can be used for analysis\n",
    "\n",
    "# # removing junk data from the dataframe to make the figures more meaningful\n",
    "\n",
    "# num.remove('date')\n",
    "# num.remove('dob')\n",
    "# num.remove('statusId')\n",
    "\n",
    "# # creating figures to show the distribution of the data from the columns of the dataframe\n",
    "\n",
    "# plt.figure(figsize=(15, 50))\n",
    "# for i, j in zip(num, range(1, len(num)+1)):\n",
    "#     plt.subplot(11, 2, j)\n",
    "#     sns.kdeplot(df[i], shade=True, color='darkred')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # importing a library to do preprocessing with\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # encoding categorical columns for faster processing in knn algorithm\n",
    "\n",
    "# for i in cat:\n",
    "#     df[i] = le.fit_transform(df[i])\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating two seperate dataframes for the training and testing data\n",
    "\n",
    "# x = df.drop('driver_name', 1)\n",
    "# y = df.driver_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # importing a library to split the data into training and testing data\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "#     x, y, test_size=0.3, random_state=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
